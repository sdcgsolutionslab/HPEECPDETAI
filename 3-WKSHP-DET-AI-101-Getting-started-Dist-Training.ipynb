{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a5e4bcf-e5b6-40a3-9135-b8d583505348",
   "metadata": {},
   "source": [
    "# Getting started with Determined, the open-source deep learning training platform - Lab 3\n",
    "\n",
    "For this part of the lab you will learn how to create an experiment that trains a single instance of the model with multiple GPUs, a process known as **Distributed Training**. Again this experiment will feature a single trial with a set of constant hyperparameters.\n",
    "\n",
    "Determined can coordinate multiple GPUs to train a deep learning model more quickly leveraging multiple GPUs on single machine or over multiple machines. Typically, ML engineers use Distributed Training to train models on larger datasets in order to improve the model performance and accuracy. This typically requires additional compute resources.\n",
    "\n",
    "Determined automatically executes **[data parallelization](https://www.oreilly.com/content/distributed-tensorflow/)** training, where data set is divided into multiple pieces and distributed across the GPUs, **without requiring any model code changes**. Each GPU has the full model and trains the model on its portion of the data. Determined ensures the coordination of the training across multiple GPUs on a single machine or multiple machines to keep the whole training task in sync.    \n",
    "\n",
    "> <font color=\"green\"> **Note:** Distributed Training performs best with complex models; therefore, the simple Iris model used in this example may not demonstrate the full benefits of using Distributed Training.</font>\n",
    "\n",
    ">_Note: To learn more about Distributed Training with Determined, check out the online documentation [here](https://docs.determined.ai/latest/training-distributed/index.html)._ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab41b4a-d8b2-4b09-a064-cec710e91ef6",
   "metadata": {},
   "source": [
    "### 1- Create an experiment to train a single instance of the model with multiple GPUs (distributed training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f696291e-bcba-48a1-9ca6-ec1f88a9846c",
   "metadata": {},
   "source": [
    "Let's run an experiment with the same model definition (same code), but this time leveraging Determined's distributed training functionality using the _distributed.yaml_ experiment configuration file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92247a4-4e2e-416f-ba7d-4fe5f568b9c2",
   "metadata": {},
   "source": [
    "#### Let's take a closer look at the experiment configuration file for distributed training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f45091-4fb7-44a1-8529-18280f25cb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ~/source_control/Code/distributed.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02b4423-1fe0-4c20-9925-8007455e8033",
   "metadata": {},
   "source": [
    "As you can see here, this configuration file is very similar to the _const.yaml_ file you used earlier. All you need to do to start a multi-GPU training workload (trial) is to specify the desired number of GPUs you want to use in the experiment configuration file and Determined takes care of the rest. For example:\n",
    "\n",
    "                                      resources:\n",
    "                                          slots_per_trial: 2\n",
    "\n",
    "With this configuration, each trial within an experiment will use **2 GPUs** to train a single model, whether leveraging 2 GPUs on a single machine or 2 GPUs across multiple machines in the Kubernetes cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accc85db-ffbf-4e5b-8dd8-a727c53c2abd",
   "metadata": {},
   "source": [
    "#### Next, submit the experiment with the experiment configuration file _distributed.yaml_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574e8b41-60aa-44c3-a69f-445d413849b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "masterUrl=!kubectl describe service determined-master-service-stagingdetai -n determinedai | grep gateway/8080 | awk '{print $3}'\n",
    "det_master = str(masterUrl)[2:-2] # we remove any potential brackets\n",
    "determined_master = \"http://\" + det_master\n",
    "#\n",
    "# launch experiment to train a single model on muliple GPUs\n",
    "!~/.local/bin/det -m {determined_master} experiment create ~/source_control/Code/distributed.yaml ~/source_control/Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5840e24-bc40-4f57-8ba9-0c978b1b78bb",
   "metadata": {},
   "source": [
    "In the lab environment, the Kubernetes worker hosts have one GPU only. The training task (trial) needs 2 GPUs as per the experiment configuration file. Therefore, Determined Master brings up two PODs, for the same trial, on two different Kubernetes worker hosts.   \n",
    "\n",
    "#### Using the command below, you will see that Determined Master has launched **two** PODs for the training task in the Kubernetes cluster with name in the form:\n",
    "\n",
    " _exp-\\<experimentID\\>-trial-\\<TriaID\\>-\\<unique-name\\>_\n",
    "\n",
    "> **Note:** Notice the Trial ID is the same for the two PODs, which means your experiment features a single trial with a fixed set of hyperparameters. \n",
    "\n",
    "> <font color=\"blue\"> **Note:** As you are sharing the same Kubernetes resources with other participants, and depending on the number of concurrent experiments running, your experiment's training task might be in **Pending** state. You might need to wait a few minutes until other experiments complete for your training task to become **Running**.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610cf4e2-b408-4e2d-93b0-6658fc9a0e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get pods -n determinedai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d543ff43-cd23-4f57-af3b-76fc8af6cd28",
   "metadata": {},
   "source": [
    "#### Run the code cell below to monitor the execution progress of the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39cfafa-83db-4658-8f5b-3c448c6f8962",
   "metadata": {},
   "outputs": [],
   "source": [
    "!~/.local/bin/det -m {determined_master} experiment list | tail -1\n",
    "# Get the experiment Id, remove spaces\n",
    "myexpId=!~/.local/bin/det -m {determined_master} experiment list | tail -1 | cut -d'|' -f 1 |  tr -d ' '\n",
    "# remove the trailer characters\n",
    "myexpId=str(myexpId)[2:-2]\n",
    "!~/.local/bin/det -m {determined_master} experiment describe {myexpId} --json | jq .[0].state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9d0800-e1cb-4eba-9ec9-6157b559edc6",
   "metadata": {},
   "source": [
    "### 2- Monitor and visualize your experiment in Determined Web User Interface\n",
    "\n",
    "To monitor the progress of the training task and access information on both training and validation performance, simply return to the Determined **WebUI**.\n",
    "\n",
    "##### From the **Dashboard**, select the most recent experiment.\n",
    "\n",
    "You should see the experiment as an **active** state. The graph is showing the training accuracy metric. You can see the graph changing in real time as the experiment runs.\n",
    "\n",
    "> <font color=\"blue\"> **Important Note:** If there are multiple concurrent participants to the workshop, your experiment might not be in active state yet. There are more experiments running than the Kubernetes cluster has GPUs. You might need to wait a few minutes until other experiments complete for your experiment to turn active. </font>\n",
    "\n",
    "From the **Metrics** menu, under **Training Metrics**, select _categorical_accuracy_ (see picture below for an example). This metric indicates the model accuracy on training data while the _val_categorical_accuracy_ indicates the model accuracy on validation data.\n",
    "\n",
    "After the experiment completes, you can see on the experiment detail page that training the model with the hyperparameter settings in `distributed.yaml` yields a validation accuracy between 93% and 97%. \n",
    "\n",
    "Scroll down to see a list of training validation workloads and their metrics for the metric types you previously selected. \n",
    "You might see one or two validation workloads with checkpoints. By default, Determined will checkpoint the most recent and the best model per training task (trial). If the most recent checkpoint is also the best checkpoint for a given trial, only one checkpoint will be saved for that trial as shown in the picture below.\n",
    "\n",
    "<img src=\"WebUI-Exp-distribute-graph.png\" height=\"520\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc516bc-8d05-4628-b827-246dd9a5ac05",
   "metadata": {},
   "source": [
    "### 3 - TensorBoard visualization\n",
    "\n",
    "You can also use [TensorBoard](https://www.tensorflow.org/tensorboard) for visualizing and inspecting the deep learning models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184233b8-3155-4f2e-a568-454f564a969e",
   "metadata": {},
   "source": [
    "#### Run the code cell below to launch the TensorBoard server instance.\n",
    "\n",
    "This may take a minute or so as Determined has to launch the Tensorboard server as a Kubernetes POD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb26f665-3e66-4e81-92ef-231762d58357",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"Start a Tensordboard server instance for your Experiment {myexpId} with TensorBoard instance ID:\")\n",
    "# start the tensorBoard server instance for the experiment\n",
    "!~/.local/bin/det -m {determined_master} tensorboard start -d {myexpId}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21ab34d-099a-4840-8551-b4781019fa80",
   "metadata": {},
   "source": [
    "#### Run the code cell below to get the Tensorboard URL for your experiment. Then, click on the link to connect.\n",
    "\n",
    ">**Note:** The associated TensorBoard server is launched as a container POD in the Kubernetes cluster. Determined proxies HTTP requests to and from the TensorBoard container through the Determined Master node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb135d8-27a9-42ba-8877-c261029ac033",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytensorboard=!~/.local/bin/det -m {determined_master} tensorboard list | grep RUNNING | cut -d'|' -f 1 |  tr -d ' '\n",
    "mytensorboard=str(mytensorboard)[2:-2]\n",
    "#print (f\"{mytensorboard}\")\n",
    "print (f\"Your tensorboard is running at http://notebooks.hpedev.io:{portUI}/proxy/{mytensorboard}/\")\n",
    "print (f\"Click on the link to connect.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801eb42d-1fec-4c3b-9560-7a12cd6bb484",
   "metadata": {},
   "source": [
    "<img src=\"TensorBoard-distribute-graph.png\" height=\"413\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c9e3cc-3267-4616-9712-b4c0f1f60a89",
   "metadata": {},
   "source": [
    "Determined created TensorBoard plots to show the training loss, validation loss, training accuracy and validation accuracy for the training task (trial).\n",
    "\n",
    "#### When you have finished with Tensorboard, run the code cell below to `kill` the Tensorboard process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da260406-7460-4f31-8237-515ba35ce628",
   "metadata": {},
   "outputs": [],
   "source": [
    "!~/.local/bin/det -m {determined_master} tensorboard kill {mytensorboard}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a7c388-54a6-4f8f-b3a1-73b605948c7e",
   "metadata": {},
   "source": [
    "### 4 - List the best model created by the training process\n",
    "By default, Determined will save the most recent and the best checkpoint per training task (trial) according to the validation metrics specified in the Searcher section of the configuration file for the experiment.\n",
    "\n",
    "* _det experiment list-checkpoints [--best] [N best checkpoints to return] \\<experiment_Id\\>_\n",
    "\n",
    ">**Note**: Upon completion of the training task, if the most recent checkpoint is also the best checkpoint for a given trial, only one checkpoint will be saved for that trial by Determined. Otherwise, two checkpoints will be saved. Other checkpoints will be automatically deleted to reclaim space.\n",
    "\n",
    "#### Run the code cell below to display the best checkpoint for your experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59096343-04b4-47a5-aab4-30244e8b1cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list the best Trial checkpoint(s) (training task):\n",
    "!~/.local/bin/det -m {determined_master} experiment list-checkpoints --best 1 {myexpId}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f5d7d0-e7ed-4706-92c0-d9bb020a4f45",
   "metadata": {},
   "source": [
    "### 5- Delete the checkpoints to reclaim some storage space in the storage file system\n",
    "\n",
    "The default **checkpoint garbage collection policy** dictates Determined to save the most recent and the best checkpoint per training task (trial). The ***save_experiment_best***, ***save_trial_best*** and ***save_trial_latest*** parameters specify which checkpoints to save. The default policy is set as follows:\n",
    "\n",
    "  * save_experiment_best:0 \n",
    "  * save_trial_best:1\n",
    "  * save_trial_latest:1\n",
    " \n",
    "#### Run the code cell below to reclaim some storage disk space by changing the default checkpoint garbage collection policy as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd39e584-2caf-4fe1-bb8b-a72f1b88888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the checkpoints data for the distributed training\n",
    "!~/.local/bin/det -m {determined_master} experiment set gc-policy --yes --save-experiment-best 0 --save-trial-best 0 --save-trial-latest 0 {myexpId}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658f8a59-040e-489c-b114-96820feaf017",
   "metadata": {},
   "source": [
    "#### Now, let's explore an Hyperparameter Optimization experiment. \n",
    "Click on Lab 4 below to open a notebook to explore Hyperparameter Optimization (HPO). \n",
    "* [Lab 4](4-WKSHP-DET-AI-101-Getting-started-HPO.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
