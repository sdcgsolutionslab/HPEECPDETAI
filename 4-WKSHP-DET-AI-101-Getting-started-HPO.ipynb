{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a5e4bcf-e5b6-40a3-9135-b8d583505348",
   "metadata": {},
   "source": [
    "# Getting started with Determined, the open-source deep learning training platform - Lab 4\n",
    "## Hyperparameter Optimization with Determined\n",
    "\n",
    "Next, let's run an experiment with the same model code, but this time leveraging Determined's hyperparameter tuning (aka Hyperparameter Optimization or **HPO**) to improve the model accuracy and let you find the best combination of hyperparameters for your particular model. \n",
    "\n",
    "ML engineers typically use HPO to efficiently determine the hyperparameter values that yield the best-performing model. Here in this lab, the hyperparameters in the experiment configuration file are specified as ranges instead of fixed values, and the `adaptive_asha` searcher method is used to explore the hyperparameter space.\n",
    "\n",
    "**With HPO, an experiment consists of multiple training tasks (trials)**. All of the trials are training the model on the same dataset and code for the DL model. However each trial uses a different configuration of hyperparameters. \n",
    "\n",
    "For this part of lab, the number of trials to run, the set of user-defined hyperparameters range, the searcher method, and the amount of data (batches or epochs) on which to train the model are defined in the experiment configuration file _adaptive.yaml_.\n",
    "\n",
    ">Note: The **searcher** is a method (an algorithm) that is used to find effective hyperparameter settings within a predifined range of hyperparameter values.\n",
    "\n",
    "More about Hyperparameter optimization and Searcher methods supported by Determined can be found [here](https://docs.determined.ai/latest/training-hyperparameter/index.html#hyperparameter-tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab41b4a-d8b2-4b09-a064-cec710e91ef6",
   "metadata": {},
   "source": [
    "### 1- Create an experiment to train multiple models as part of a hyperparameter search, using Determined hyperparameter optimization (HPO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f696291e-bcba-48a1-9ca6-ec1f88a9846c",
   "metadata": {},
   "source": [
    "Let's run an experiment with the same model definition (same code), but this time leveraging Determined's hyperparameter optimization functionality using the _adaptive.yaml_ experiment configuration file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92247a4-4e2e-416f-ba7d-4fe5f568b9c2",
   "metadata": {},
   "source": [
    "#### Let's take a closer look at the experiment configuration file for HPO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f45091-4fb7-44a1-8529-18280f25cb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ~/source_control/Code/adaptive.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbc4d1c-15ea-47a1-84fe-c3f6c32247d9",
   "metadata": {},
   "source": [
    "----- to be continued from here ------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02b4423-1fe0-4c20-9925-8007455e8033",
   "metadata": {},
   "source": [
    "As you can see here, this configuration file is very similar to the _const.yaml_ file you used earlier. All you need to do to start a multi-GPU training workload (trial) is to specify the desired number of GPUs you want to use in the experiment configuration file and Determined takes care of the rest. For example:\n",
    "\n",
    "                                      resources:\n",
    "                                          slots_per_trial: 2\n",
    "\n",
    "With this configuration, each trial within an experiment will use **2 GPUs** to train a single model, whether leveraging 2 GPUs on a single machine or 2 GPUs across multiple machines in the Kubernetes cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accc85db-ffbf-4e5b-8dd8-a727c53c2abd",
   "metadata": {},
   "source": [
    "#### Next, submit the experiment with the experiment configuration file _distributed.yaml_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574e8b41-60aa-44c3-a69f-445d413849b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "masterUrl=!kubectl describe service determined-master-service-stagingdetai -n determinedai | grep gateway/8080 | awk '{print $3}'\n",
    "det_master = str(masterUrl)[2:-2] # we remove any potential brackets\n",
    "determined_master = \"http://\" + det_master\n",
    "#\n",
    "# Launch experiment to train the model with hyperparameter tuning\n",
    "!~/.local/bin/det -m {determined_master} experiment create ~/source_control/Code/adaptive.yaml ~/source_control/Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5840e24-bc40-4f57-8ba9-0c978b1b78bb",
   "metadata": {},
   "source": [
    "In the lab environment, the Kubernetes worker hosts have one GPU only. The training task (trial) needs 2 GPUs as per the experiment configuration file. Therefore, Determined Master brings up two PODs, for the same trial, on two different Kubernetes worker hosts.   \n",
    "\n",
    "#### Using the command below, you will see that Determined Master has launched **two** PODs for the training task in the Kubernetes cluster with name in the form:\n",
    "\n",
    " _exp-\\<experimentID\\>-trial-\\<TriaID\\>-\\<unique-name\\>_\n",
    "\n",
    "> Notice the Trial ID is the same for the two PODs, which means your experiment features a single trial with a fixed set of hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610cf4e2-b408-4e2d-93b0-6658fc9a0e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get pods -n determinedai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d543ff43-cd23-4f57-af3b-76fc8af6cd28",
   "metadata": {},
   "source": [
    "#### Run the code cell below to monitor the execution progress of the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39cfafa-83db-4658-8f5b-3c448c6f8962",
   "metadata": {},
   "outputs": [],
   "source": [
    "!~/.local/bin/det -m {determined_master} experiment list | tail -1\n",
    "# Get the experiment Id, remove spaces\n",
    "myexpId=!~/.local/bin/det -m {determined_master} experiment list | tail -1 | cut -d'|' -f 1 |  tr -d ' '\n",
    "# remove the trailer characters\n",
    "myexpId=str(myexpId)[2:-2]\n",
    "!~/.local/bin/det -m {determined_master} experiment describe {myexpId} --json | jq .[0].state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9d0800-e1cb-4eba-9ec9-6157b559edc6",
   "metadata": {},
   "source": [
    "### 2- Monitor and visualize your experiment in Determined Web User Interface\n",
    "\n",
    "To monitor the progress of the training task and access information on both training and validation performance, simply return to the Determined **WebUI**.\n",
    "\n",
    "##### From the **Dashboard**, select the most recent experiment.\n",
    "\n",
    "You should see the experiment as an active state. The graph is showing the training accuracy metric. You can see the graph changing in real time as the experiment runs.\n",
    "\n",
    "From the **Metrics** menu, under **Training Metrics**, select _categorical_accuracy_ (see picture below for an example). This metric indicates the model accuracy on training data while the _val_categorical_accuracy_ indicates the model accuracy on validation data.\n",
    "\n",
    "After the experiment completes, you can see on the experiment detail page that training the model with the hyperparameter settings in `distributed.yaml` yields a validation accuracy between 93% and 97%. \n",
    "\n",
    "Scroll down to see a list of training validation workloads and their metrics for the metric types you previously selected. \n",
    "You might see one or two validation workloads with checkpoints. By default, Determined will checkpoint the most recent and the best model per training task (trial). If the most recent checkpoint is also the best checkpoint for a given trial, only one checkpoint will be saved for that trial as shown in the picture below.\n",
    "\n",
    "<img src=\"WebUI-Exp-distribute-graph.png\" height=\"520\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc516bc-8d05-4628-b827-246dd9a5ac05",
   "metadata": {},
   "source": [
    "### 3 - TensorBoard visualization\n",
    "\n",
    "You can also use [TensorBoard](https://www.tensorflow.org/tensorboard) for visualizing and inspecting the deep learning models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184233b8-3155-4f2e-a568-454f564a969e",
   "metadata": {},
   "source": [
    "#### Run the code cell below to launch the TensorBoard server instance.\n",
    "\n",
    "This may take a minute or so as Determined has to launch the Tensorboard server as a Kubernetes POD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb26f665-3e66-4e81-92ef-231762d58357",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"Start a Tensordboard server instance for your Experiment {myexpId} with TensorBoard instance ID:\")\n",
    "# start the tensorBoard server instance for the experiment\n",
    "!~/.local/bin/det -m {determined_master} tensorboard start -d {myexpId}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21ab34d-099a-4840-8551-b4781019fa80",
   "metadata": {},
   "source": [
    "#### Run the code cell below to get the Tensorboard URL for your experiment. Then, click on the link to connect.\n",
    "\n",
    ">**Note:** The associated TensorBoard server is launched as a container POD in the Kubernetes cluster. Determined proxies HTTP requests to and from the TensorBoard container through the Determined Master node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb135d8-27a9-42ba-8877-c261029ac033",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytensorboard=!~/.local/bin/det -m {determined_master} tensorboard list | grep RUNNING | cut -d'|' -f 1 |  tr -d ' '\n",
    "mytensorboard=str(mytensorboard)[2:-2]\n",
    "#print (f\"{mytensorboard}\")\n",
    "print (f\"Your tensorboard is running at http://notebooks.hpedev.io:{portUI}/proxy/{mytensorboard}/\")\n",
    "print (f\"Click on the link to connect.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801eb42d-1fec-4c3b-9560-7a12cd6bb484",
   "metadata": {},
   "source": [
    "<img src=\"TensorBoard-distribute-graph.png\" height=\"413\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c9e3cc-3267-4616-9712-b4c0f1f60a89",
   "metadata": {},
   "source": [
    "Determined created TensorBoard plots to show the training loss, validation loss, training accuracy and validation accuracy for the training task (trial).\n",
    "\n",
    "#### When you have finished with Tensorboard, run the code cell below to `kill` the Tensorboard process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da260406-7460-4f31-8237-515ba35ce628",
   "metadata": {},
   "outputs": [],
   "source": [
    "!~/.local/bin/det -m {determined_master} tensorboard kill {mytensorboard}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a7c388-54a6-4f8f-b3a1-73b605948c7e",
   "metadata": {},
   "source": [
    "### 4 - List the best model created by the training process\n",
    "By default, Determined will save the most recent and the best checkpoint per training task (trial) according to the validation metrics specified in the Searcher section of the configuration file for the experiment.\n",
    "\n",
    "* _det experiment list-checkpoints [--best] [N best checkpoints to return] \\<experiment_Id\\>_\n",
    "\n",
    ">**Note**: Upon completion of the training task, if the most recent checkpoint is also the best checkpoint for a given trial, only one checkpoint will be saved for that trial by Determined. Otherwise, two checkpoints will be saved. Other checkpoints will be automatically deleted to reclaim space.\n",
    "\n",
    "#### Run the code cell below to display the best checkpoint for your experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59096343-04b4-47a5-aab4-30244e8b1cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list the best Trial checkpoint(s) (training task):\n",
    "!~/.local/bin/det -m {determined_master} experiment list-checkpoints --best 1 {myexpId}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f5d7d0-e7ed-4706-92c0-d9bb020a4f45",
   "metadata": {},
   "source": [
    "### 5- Delete the checkpoints to reclaim some storage space in the storage file system\n",
    "\n",
    "The default **checkpoint garbage collection policy** dictates Determined to save the most recent and the best checkpoint per training task (trial). The ***save_experiment_best***, ***save_trial_best*** and ***save_trial_latest*** parameters specify which checkpoints to save. The default policy is set as follows:\n",
    "\n",
    "  * save_experiment_best:0 \n",
    "  * save_trial_best:1\n",
    "  * save_trial_latest:1\n",
    " \n",
    "#### Run the code cell below to reclaim some storage disk space by changing the default checkpoint garbage collection policy as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd39e584-2caf-4fe1-bb8b-a72f1b88888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the checkpoints data for the distributed training\n",
    "!~/.local/bin/det -m {determined_master} experiment set gc-policy --yes --save-experiment-best 0 --save-trial-best 0 --save-trial-latest 0 {myexpId}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658f8a59-040e-489c-b114-96820feaf017",
   "metadata": {},
   "source": [
    "#### Now, logout from your local Jupyter Notebook and go back to the JupyterHub notebook to perform some cleanup and for a wrap up of the workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8538fc71-e74a-4904-b556-8d8bde082265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
